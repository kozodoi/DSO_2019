{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. SETTINGS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LofLYLANetP5"
   },
   "source": [
    "# settings for Google Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "import os\n",
    "os.chdir(\"/gdrive/My Drive/Data Science Olympics/codes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "import scipy.stats\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "import functions\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas options\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dark background style\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# garbage collection\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import CSV\n",
    "df = pd.read_csv('../data/data_v1.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target variable\n",
    "target = 'duration'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partitioning\n",
    "train = df[df[target].isnull() == False]\n",
    "test  = df[df[target].isnull() == True]\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target variable\n",
    "y = train.sort_values('id')[target]\n",
    "test_ids = test['id']\n",
    "classes = y.unique()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT OOF AND TEST PREDS\n",
    "\n",
    "# which model to stack?\n",
    "model = 'stack'\n",
    "\n",
    "# performance threshold\n",
    "#min_profit = 250\n",
    "\n",
    "# list names\n",
    "names = sorted(os.listdir('../oof_preds_stack2'))\n",
    "#names = [n for n in names if int(n[n.rindex('_')+1:-4]) > min_profit]\n",
    "names = [s for s in names if model in s]\n",
    "\n",
    "# preprocessing loop\n",
    "for name in names:\n",
    "\n",
    "    # load preds\n",
    "    tmp_tr = pd.read_csv('../oof_preds_stack2/'   + str(name))\n",
    "    tmp_te = pd.read_csv('../submissions/' + str(name))\n",
    "\n",
    "    # sort OOF preds by ID\n",
    "    if 'id' in tmp_tr:\n",
    "        tmp_tr = tmp_tr.sort_values('id')\n",
    "        tr_id  = tmp_tr['id']\n",
    "        del tmp_tr['id']\n",
    "        \n",
    "    # extract test IDs\n",
    "    if 'id' in tmp_te:\n",
    "        tmp_te = tmp_te.sort_values('id')\n",
    "        te_id  = tmp_te['id']\n",
    "        del tmp_te['id']\n",
    "        \n",
    "    # rename columns\n",
    "    tmp_tr.columns = [str(name) + '_' + str(l.replace('class_', '')) for l in list(tmp_tr.columns)]    \n",
    "    tmp_te.columns = [str(name) + '_' + str(l.replace('class_', '')) for l in list(tmp_te.columns)]  \n",
    "\n",
    "    # cbind data\n",
    "    if name == names[0]:     \n",
    "        train = tmp_tr \n",
    "        test  = tmp_te\n",
    "    else:\n",
    "        train = pd.concat([train, tmp_tr], axis = 1)\n",
    "        test  = pd.concat([test,  tmp_te], axis = 1)\n",
    "        \n",
    "\n",
    "# put back id\n",
    "train.insert(0, column = 'id', value = tr_id)\n",
    "test.insert(0,  column = 'id', value = te_id)\n",
    "        \n",
    "# display information\n",
    "print('- Train shape:', train.shape)\n",
    "print('- Test shape:',  test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. BLENDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep best model per seed\n",
    "models = []\n",
    "for seed in range(1000, 1010):\n",
    "    seed_models  = [x for x in list(train.columns) if str(seed) in x]\n",
    "    seed_profits = [x[-7:-4] for x in seed_models]\n",
    "    best_model   = seed_models[np.argmax(seed_profits)]\n",
    "    models.append(best_model)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average probs for differnt classes\n",
    "for cl in ['_0', '_1', '_2']:\n",
    "    \n",
    "    # train\n",
    "    preds = [l for l in list(train.columns) if l.endswith(cl)]\n",
    "    blend = train[preds].mean(axis = 1)\n",
    "    train['blend_' + cl] = blend\n",
    "    \n",
    "    # test\n",
    "    preds = [l for l in list(test.columns) if l.endswith(cl)]\n",
    "    blend = test[preds].mean(axis = 1)\n",
    "    test['blend_' + cl] = blend\n",
    "    \n",
    "# extract predictions\n",
    "preds_oof  = train.filter(like = 'blend', axis = 1)\n",
    "preds_test = test.filter(like  = 'blend', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try different ensembles\n",
    "#from scipy.stats.mstats import gmean\n",
    "#armean_tr = np.array(train[models].mean(axis    = 1))\n",
    "#median_tr = np.array(train[models].median(axis  = 1))\n",
    "#gemean_tr = gmean(np.array(train[models]), axis = 1)\n",
    "#min_tr    = np.array(train[models].min(axis     = 1))\n",
    "#max_tr    = np.array(train[models].max(axis     = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check performance\n",
    "cv_perf = np.round(log_loss(y, preds_oof), 6)\n",
    "cv_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Tt_FxCwG4VF"
   },
   "outputs": [],
   "source": [
    "# file name\n",
    "model = 'blend'\n",
    "perf  = str(round(cv_perf, 6))[2:7]\n",
    "name  = model + '_' + perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gukkBbc9G4VH"
   },
   "outputs": [],
   "source": [
    "# export submission\n",
    "#sub = pd.DataFrame({'id': test['id'], 'duration': preds_test})\n",
    "#sub.to_csv('../submissions/' + str(name) + '.csv', index = False)\n",
    "#sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1cJ8GWH7G4VJ"
   },
   "outputs": [],
   "source": [
    "# export submission\n",
    "sub = pd.DataFrame(preds_test)\n",
    "sub.columns = ['id', '0', '1', '2']\n",
    "sub.to_csv('../submissions/' + str(name) + '.csv', index = False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KSlPhL4dG4VO"
   },
   "outputs": [],
   "source": [
    "# check correlation with previous submission\n",
    "#prev_sub = pd.read_csv('../submissions/lgb_v8_375.csv')\n",
    "#cor = np.sum(prev_sub[target] == sub.reset_index()[target]) / len(sub)\n",
    "#print(\"Share of the same predictions: \" + str(np.round(cor, 6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KSlPhL4dG4VO"
   },
   "outputs": [],
   "source": [
    "# check correlation with previous submission\n",
    "prev_sub = pd.read_csv('../submissions/lgb_v1_96790.csv')\n",
    "pd.Series(np.diag(sub.apply(lambda x: prev_sub.corrwith(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit to QSCORE\n",
    "comment = ''\n",
    "submit_prediction(sub, sep = ',', index = False, comment = str(comment) + ' - ' + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
