{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "import scipy.stats\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "import functions\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas options\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dark background style\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# garbage collection\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import CSV\n",
    "df = pd.read_csv('../data/data_v1.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target variable\n",
    "target = 'duration'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partitioning\n",
    "train = df[df[target].isnull() == False]\n",
    "test  = df[df[target].isnull() == True]\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target variable\n",
    "y = train.sort_values('id')[target]\n",
    "test_ids = test['id']\n",
    "classes = y.unique()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT OOF AND TEST PREDS\n",
    "\n",
    "# which model to stack?\n",
    "model = 'stack'\n",
    "\n",
    "# performance threshold\n",
    "#min_profit = 250\n",
    "\n",
    "# list names\n",
    "names = sorted(os.listdir('../oof_preds_stack'))\n",
    "#names = [n for n in names if int(n[n.rindex('_')+1:-4]) > min_profit]\n",
    "names = [s for s in names if model in s]\n",
    "\n",
    "# preprocessing loop\n",
    "for name in names:\n",
    "\n",
    "    # load preds\n",
    "    tmp_tr = pd.read_csv('../oof_preds_stack/'   + str(name))\n",
    "    tmp_te = pd.read_csv('../submissions/' + str(name))\n",
    "\n",
    "    # sort OOF preds by ID\n",
    "    if 'id' in tmp_tr:\n",
    "        tmp_tr = tmp_tr.sort_values('id')\n",
    "        tr_id  = tmp_tr['id']\n",
    "        del tmp_tr['id']\n",
    "        \n",
    "    # extract test IDs\n",
    "    if 'id' in tmp_te:\n",
    "        tmp_te = tmp_te.sort_values('id')\n",
    "        te_id  = tmp_te['id']\n",
    "        del tmp_te['id']\n",
    "        \n",
    "    # rename columns\n",
    "    tmp_tr.columns = [str(name) + '_' + str(l.replace('class_', '')) for l in list(tmp_tr.columns)]    \n",
    "    tmp_te.columns = [str(name) + '_' + str(l.replace('class_', '')) for l in list(tmp_te.columns)]  \n",
    "\n",
    "    # cbind data\n",
    "    if name == names[0]:     \n",
    "        train = tmp_tr \n",
    "        test  = tmp_te\n",
    "    else:\n",
    "        train = pd.concat([train, tmp_tr], axis = 1)\n",
    "        test  = pd.concat([test,  tmp_te], axis = 1)\n",
    "        \n",
    "\n",
    "# put back id\n",
    "train.insert(0, column = 'id', value = tr_id)\n",
    "test.insert(0,  column = 'id', value = te_id)\n",
    "        \n",
    "# display information\n",
    "print('- Train shape:', train.shape)\n",
    "print('- Test shape:',  test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop bad features\n",
    "excluded_feats = ['id']\n",
    "features = [f for f in train.columns if f not in excluded_feats]\n",
    "print(train[features].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# range of seeds\n",
    "shift = 1000\n",
    "iters = 10\n",
    "seeds = range(shift + 0, shift + iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### MODELING LOOP WOTH DIFFERENT SEEDS\n",
    "for seed in seeds:\n",
    "\n",
    "    \n",
    "    ##### PARAMETERS\n",
    "\n",
    "    # settings\n",
    "    cores = 4\n",
    "\n",
    "    # cross-validation\n",
    "    num_folds = 5\n",
    "    shuffle   = True\n",
    "\n",
    "    # muner of rounds\n",
    "    max_rounds = 300\n",
    "    stopping   = 100\n",
    "    verbose    = 0\n",
    "\n",
    "    # LGB parameters\n",
    "    lgb_params = {\n",
    "        'boosting_type':     'gbdt',\n",
    "        'objective':         'multiclass',\n",
    "        'metric':            'multi_logloss',\n",
    "        'num_class':         len(classes),\n",
    "        'bagging_fraction':  0.9,\n",
    "        'feature_fraction':  0.9,\n",
    "        'lambda_l1':         0.1,\n",
    "        'lambda_l2':         0.1,\n",
    "        'min_split_gain':    0.01,\n",
    "        'min_child_weight':  1,\n",
    "        'min_child_samples': 1,\n",
    "        'silent':            True,\n",
    "        'verbosity':         -1,\n",
    "        'learning_rate':     0.05,\n",
    "        'max_depth':         5,\n",
    "        'num_leaves':        70,\n",
    "        'scale_pos_weight':  1,\n",
    "        'n_estimators':      max_rounds,\n",
    "        'n_jobs' :           cores,\n",
    "        'random_state':      seed,\n",
    "    }\n",
    "\n",
    "    # data partitinoing\n",
    "    folds = StratifiedKFold(n_splits = num_folds, random_state = seed, shuffle = shuffle)\n",
    "\n",
    "    # placeholders\n",
    "    clfs = []\n",
    "    valid_perf  = np.zeros(num_folds) \n",
    "    #preds_test   = np.zeros(test.shape[0])\n",
    "    #preds_oof    = np.zeros(train.shape[0])\n",
    "    preds_oof  = np.zeros((len(train), len(classes)))\n",
    "    preds_test = np.zeros((len(test),  len(classes)))\n",
    "    \n",
    "    # print random seed\n",
    "    print('----------------------')\n",
    "    print('SEED = %.0f' % seed)\n",
    "    print('----------------------')\n",
    "    \n",
    "    ##### CROSS-VALIDATION LOOP\n",
    "    for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train, y)):\n",
    "\n",
    "        # data partitioning\n",
    "        trn_x, trn_y = train[features].iloc[trn_idx], y.iloc[trn_idx]\n",
    "        val_x, val_y = train[features].iloc[val_idx], y.iloc[val_idx]\n",
    "        test_x       = test[features]\n",
    "\n",
    "        # train lightGBM\n",
    "        clf = lgb.LGBMClassifier(**lgb_params) \n",
    "        clf = clf.fit(trn_x, trn_y, \n",
    "                      eval_set              = [(trn_x, trn_y), (val_x, val_y)], \n",
    "                      early_stopping_rounds = stopping,\n",
    "                      verbose               = verbose)\n",
    "        clfs.append(clf)\n",
    "\n",
    "        # find the best iteration\n",
    "        best_iter = clf.best_iteration_\n",
    "\n",
    "        # save predictions\n",
    "        #preds_oof[val_idx]    = clf.predict_proba(val_x,  num_iteration = best_iter)[:, 1]\n",
    "        #valid_profit[n_fold]  = log_loss(y, preds_oof)\n",
    "        #preds_test           += clf.predict_proba(test_x, num_iteration = best_iter)[:, 1] / folds.n_splits \n",
    "\n",
    "        # save predictions\n",
    "        preds_oof[val_idx, :] = clf.predict_proba(val_x, num_iteration = best_iter)\n",
    "        valid_perf[n_fold]    = log_loss(y[val_idx], preds_oof[val_idx, :])\n",
    "        preds_test           += clf.predict_proba(test_x, num_iteration = best_iter) / folds.n_splits \n",
    "\n",
    "        # print performance\n",
    "        print('- FOLD%2d: LOGLOSS = %.6f' % (n_fold + 1, valid_perf[n_fold]))\n",
    "\n",
    "        # clear memory\n",
    "        del trn_x, trn_y, val_x, val_y\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "    # print overall performance    \n",
    "    cv_perf = np.mean(valid_perf)\n",
    "    print('--------------------------------')\n",
    "    print('MEAN LOGLOSS = %.6f' % cv_perf)\n",
    "    print('--------------------------------')\n",
    "\n",
    "\n",
    "    ##### GENERATE SUBMISSION\n",
    "\n",
    "    # file name\n",
    "    model = 'stacking_seed'\n",
    "    perf  = str(round(cv_perf, 6))[2:7]\n",
    "    name  = model + str(seed) + '_profit_' + perf\n",
    "       \n",
    "    # export OOF preds\n",
    "    oof = pd.DataFrame(preds_oof)\n",
    "    oof.insert(0, column = 'id', value = train['id'].reset_index(drop = True))\n",
    "    oof.to_csv('../oof_preds_stack2/' + str(name) + '.csv', index = False)\n",
    "\n",
    "    # export submission\n",
    "    sub = pd.DataFrame(preds_test)\n",
    "    sub.insert(0, column = 'id', value = test['id'].reset_index(drop = True))\n",
    "    sub.to_csv('../submissions/' + str(name) + '.csv', index = False)\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
